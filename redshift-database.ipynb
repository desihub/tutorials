{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redshift Database Tutorial\n",
    "\n",
    "## Abstract\n",
    "\n",
    "This tutorial will cover the basics of using the redshift database, which is loaded from the outputs of the DESI pipeline.  Currently, this is based on reference run 19.9, and uses a SQLite database.  However, by using [SQLAlchemy](http://www.sqlalchemy.org/), we abstract away the details of the database.  In other words only tiny changes to the initial configuration are needed to run the same code with a [PostgreSQL](https://www.postgresql.org/) database.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "This tutorial uses data from the 19.9 reference run (`/global/project/projectdirs/desi/datachallenge/reference_runs/19.9`), and the **DESI master** kernel.\n",
    "\n",
    "## Initial Setup\n",
    "\n",
    "This just imports everything we need and sets up paths and environment variables so we can find things.  The paths are based on the [minitest notebook](https://github.com/desihub/desitest/blob/master/mini/minitest.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Imports\n",
    "#\n",
    "%matplotlib inline\n",
    "import os\n",
    "from argparse import Namespace\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import fontManager, FontProperties\n",
    "from sqlalchemy import __version__ as sqlalchemy_version\n",
    "from sqlalchemy import inspect\n",
    "from sqlalchemy.sql import func\n",
    "from astropy.constants import c as lightspeed\n",
    "from astropy.table import Table, MaskedColumn\n",
    "#\n",
    "# DESI software\n",
    "#\n",
    "from desitarget.targetmask import (desi_mask, mws_mask, bgs_mask)\n",
    "from desisim.spec_qa import redshifts as dsq_z\n",
    "from desispec import __version__ as desispec_version\n",
    "import desispec.database.redshift as db\n",
    "#\n",
    "# Paths to files, etc.\n",
    "#\n",
    "reference_run = '19.9'\n",
    "basedir = os.path.join('/global/project/projectdirs/desi/datachallenge/reference_runs', reference_run)\n",
    "surveydir = os.environ['DESISURVEY_OUTPUT'] = os.path.join(basedir, 'survey')\n",
    "targetdir = os.path.join(basedir, 'targets')\n",
    "fibassigndir = os.path.join(basedir, 'fiberassign')\n",
    "os.environ['DESI_SPECTRO_REDUX'] = os.path.join(basedir, 'spectro', 'redux')\n",
    "os.environ['DESI_SPECTRO_SIM'] = os.path.join(basedir, 'spectro', 'sim')\n",
    "os.environ['PIXPROD'] = 'mini'\n",
    "os.environ['SPECPROD'] = 'mini'\n",
    "reduxdir = os.path.join(os.environ['DESI_SPECTRO_REDUX'], os.environ['SPECPROD'])\n",
    "simdatadir = os.path.join(os.environ['DESI_SPECTRO_SIM'], os.environ['PIXPROD'])\n",
    "os.environ['DESI_SPECTRO_DATA'] = simdatadir\n",
    "#\n",
    "# Working directory.\n",
    "#\n",
    "workingdir = os.getcwd()\n",
    "print(desispec_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Database\n",
    "\n",
    "### Introduction\n",
    "\n",
    "Although there is already a database loaded from the 19.9 results, we'll still go through the exercise of loading a new database directly from the 19.9 files.  It should take less than one minute to load.\n",
    "\n",
    "If you've *already* loaded the database, skip the cell immediately below and jump to the cell with the comment \"If the database already exists...\".\n",
    "\n",
    "The files that get loaded are:\n",
    "\n",
    "* `survey/exposures.fits`.  This records the data about individual exposures.\n",
    "  - Database table name: `obslist`.\n",
    "  - SQLAlchemy object: `db.ObsList`.\n",
    "  - Primary key: `expid`.\n",
    "* `targets/truth.fits`.  The truth table.  What is the *true* redshift of this object?\n",
    "  - Database table name: `truth`.\n",
    "  - SQLAlchemy object: `db.Truth`.\n",
    "  - Primary key: `targetid`.\n",
    "* `targets/target.fits`. The target table.  What objects are we *trying* to observe?\n",
    "  - Database table name: `target`.\n",
    "  - SQLAlchemy object: `db.Target`.\n",
    "  - Primary key: `targetid`.\n",
    "* `spectro/redux/mini/zcatalog-mini.fits`. The actual redshift catalog; the results of the pipeline.\n",
    "  - Database table name: `zcat`.\n",
    "  - SQLAlchemy object: `db.ZCat`.\n",
    "  - Primary key: `targetid`.\n",
    "* `fiberassign/tile-*.fits`. The fiber assignment data.  What fiber ended up on what target?\n",
    "  - Database table name: `fiberassign`.\n",
    "  - SQLAlchemy object: `db.FiberAssign`.\n",
    "  - Primary key: (`tileid`, `fiber`).\n",
    "\n",
    "### Create the Empty Database\n",
    "\n",
    "We'll be using a SQLite database, just ignore the return value of `db.setup_db()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgresql = db.setup_db(dbfile=os.path.join(workingdir, 'minitest-{0}.db'.format(reference_run)),\n",
    "                         overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The List of Exposures\n",
    "\n",
    "The `expand` option renames the column `PASS` to `passnum` in the database.  This is to prevent any collisions with the Python statement `pass`.\n",
    "\n",
    "Calibration exposures do not have a well-defined value of (RA, Dec), so in the file, they might be set to NaN.  The `rowfilter` option eliminates those rows, and the warning can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.load_file(os.path.join(surveydir, 'exposures.fits'), db.ObsList, hdu='EXPOSURES', expand={'PASS': 'passnum'},\n",
    "             rowfilter=lambda x: (x['PROGRAM'] != 'CALIB'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Truth and Target Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.load_file(os.path.join(targetdir, 'truth-dark.fits'), db.Truth, hdu='TRUTH')\n",
    "for h in ('BGS', 'ELG', 'LRG', 'QSO', 'STAR', 'WD'):\n",
    "    db.update_truth(os.path.join(targetdir, 'truth-dark.fits'), 'TRUTH_' + h)\n",
    "db.load_file(os.path.join(targetdir, 'targets-dark.fits'), db.Target, hdu='TARGETS',\n",
    "             expand={'DCHISQ': ('dchisq_psf', 'dchisq_rex', 'dchisq_dev', 'dchisq_exp', 'dchisq_comp',)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Redshift Catalog\n",
    "\n",
    "In this case the expand option expands an array-valued column into corresponding scalar database columns.\n",
    "We also need to filter out some (simulated!) bad fibers that don't have a valid TARGETID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.load_file(os.path.join(reduxdir, 'zcatalog-mini.fits'), db.ZCat, hdu=\"ZCATALOG\",\n",
    "             expand={'COEFF': ('coeff_0', 'coeff_1', 'coeff_2', 'coeff_3', 'coeff_4',\n",
    "                               'coeff_5', 'coeff_6', 'coeff_7', 'coeff_8', 'coeff_9',)},\n",
    "             rowfilter=lambda x: ((x['TARGETID'] != 0) & (x['TARGETID'] != -1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fiberassign Outputs\n",
    "\n",
    "The fiberassign outputs are not contained in a single file so a special loading function is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.load_fiberassign(fibassigndir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database Already Exists?\n",
    "\n",
    "If the database already exists, just skip to this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgresql = db.setup_db(dbfile=os.path.join(workingdir, 'minitest-{0}.db'.format(reference_run)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning About the Tables\n",
    "\n",
    "The tables in the database are listed above.  To inspect an individual table, you can use the `__table__` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Print the table columns and their types.\n",
    "#\n",
    "[(c.name, c.type) for c in db.ZCat.__table__.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also `inspect()` the database.  For details see [here](http://docs.sqlalchemy.org/en/latest/core/inspection.html?highlight=inspect#module-sqlalchemy.inspection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspector = inspect(db.engine)\n",
    "for table_name in inspector.get_table_names():\n",
    "    print(table_name)\n",
    "    for column in inspector.get_columns(table_name):\n",
    "        print(\"Column: {name} {type}\".format(**column))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "* What is the type of the `night` column of the `obslist` table?\n",
    "* What is the primary key of the `obslist` table?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Queries\n",
    "\n",
    "Queries are set up with the `.query()` method on Session objects.  In this case, there's a prepared Session object called `db.dbSession`.  `.filter()` corresponds to a `WHERE` clause in SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Select ELG targets.  Note the special way we obtain the bitwise and operator.\n",
    "#\n",
    "q = db.dbSession.query(db.Target).filter(db.Target.desi_target.op('&')(desi_mask.ELG) != 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(row.targetid, row.desi_target, row.ra, row.dec) for row in q[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "* How many objects in the `zcat` table have `spectype` 'GALAXY'?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Join\n",
    "\n",
    "Now let's `JOIN` two tables.  In this case, we'll look at true redshift versus measured redshift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = db.dbSession.query(db.Truth, db.ZCat).filter(db.Truth.targetid == db.ZCat.targetid).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(row.Truth.truez, row.ZCat.z) for row in q[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# A very similar plot appears in the tutorial notebook dc17a-truth.\n",
    "#\n",
    "dv = lightspeed.to('km / s') * np.array([(row.ZCat.z - row.Truth.truez) / (1.0 + row.Truth.truez) for row in q])\n",
    "ttype = [row.Truth.templatetype for row in q]\n",
    "fig, axes = plt.subplots(2, 3, figsize=(9,6), dpi=100)\n",
    "for k, objtype in enumerate(set(ttype)):\n",
    "    i = k % 2\n",
    "    j = k % 3\n",
    "    # s = axes[i].subplot(2, 3, 1+i)\n",
    "    ii = np.array(ttype) == objtype\n",
    "    axes[i][j].hist(dv[ii], 50, (-100, 100))\n",
    "    axes[i][j].set_xlabel('{} dv [km/s]'.format(objtype))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "* For QSOs, plot true redshift versus observed redshift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A More Complicated Join\n",
    "\n",
    "Let's do a consistency check: do the number of observations in the `db.ZCat` table match the corresponding number of exposures and fiber assignments?\n",
    "\n",
    "In this example, we're using `sqlalchemy.sql.func` to get the equivalent of `COUNT(*)` and a subquery that itself is a multi-table join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = db.dbSession.query(db.ZCat.targetid, db.FiberAssign.tileid, db.ObsList.expid, func.count('*').label('n_assign'))\\\n",
    "                .filter(db.ZCat.targetid == db.FiberAssign.targetid)\\\n",
    "                .filter(db.FiberAssign.tileid == db.ObsList.tileid)\\\n",
    "                .group_by(db.ZCat.targetid).subquery()\n",
    "q2 = db.dbSession.query(db.ZCat, q1)\\\n",
    "                 .filter(db.ZCat.targetid == q1.c.targetid)\\\n",
    "                 .order_by(db.ZCat.targetid).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Examine the structure of what is returned.\n",
    "#\n",
    "q2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# If everything matches up, this should return True.\n",
    "#\n",
    "all([row.ZCat.numexp == row.n_assign for row in q2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "* What is the distribution of number of exposures?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updates\n",
    "\n",
    "It turns out that the QSO templates in the Truth table are not as useful as they could be.  They should be split into two classes: 'QSO_L' For Lyman-alpha QSOs with redshift >= 2.1 and 'QSO_T' for all other QSOs with redshift < 2.1.\n",
    "\n",
    "Also note that, currently, strings get loaded into the database with padding, but it's easy to deal with that with a `LIKE` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = db.dbSession.query(db.Truth).filter(db.Truth.truez >= 2.1).filter(db.Truth.templatetype.like('QSO%')).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Updates are very easy.\n",
    "#\n",
    "for row in q:\n",
    "    row.templatetype = 'QSO_L'\n",
    "#\n",
    "# Commit the changes to the database.\n",
    "#\n",
    "db.dbSession.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Did the change happen?\n",
    "#\n",
    "q = db.dbSession.query(db.Truth).filter(db.Truth.truez >= 2.1).filter(db.Truth.templatetype.like('QSO%')).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all([row.templatetype == 'QSO_L' for row in q])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "* Do the same for 'QSO_T'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency Studies\n",
    "\n",
    "In `desisim.spec_qa.redshifts` there is a lot of functionality for matching redshifts to the truth table (file).  This matching is done automatically for us just by doing a join.  Also note that we're letting the database compute the value of `dz`.\n",
    "\n",
    "We're going to cheat a little bit and convert the database output into an `astropy.table.Table` that can be understood by the `desisim.spec_qa` machinery.  No reason to waste perfectly good code!  In the future, this machinery can & should be updated to use database inputs directly.  Who wants to work on that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = db.dbSession.query(db.Truth, db.Target, db.ZCat, ((db.ZCat.z - db.Truth.truez)/(1.0 + db.Truth.truez)).label('dz'))\\\n",
    "                .filter(db.Truth.targetid == db.ZCat.targetid).filter(db.Target.targetid == db.ZCat.targetid).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truth_query_to_table(q):\n",
    "    \"\"\"Convert a query result into a Table, so that it can be used with functions in ``desisim.spec_qa.redshifts.``\n",
    "    \"\"\"\n",
    "    t = Table()\n",
    "    columns = list()\n",
    "    mask = [False]*len(q)\n",
    "    for c in db.Truth.__table__.columns:\n",
    "        if c.name == 'truespectype' or c.name == 'templatetype':\n",
    "            columns.append(MaskedColumn([np.char.rstrip(getattr(row.Truth, c.name)) for row in q], name=c.name.upper(), mask=mask))\n",
    "        else:\n",
    "            columns.append(MaskedColumn([getattr(row.Truth, c.name) for row in q], name=c.name.upper(), mask=mask))\n",
    "    for c in ('desi_target', 'bgs_target', 'mws_target'):\n",
    "        columns.append(MaskedColumn([getattr(row.Target, c) for row in q], name=c.upper(), mask=mask))\n",
    "    for c in ('z', 'zerr', 'zwarn', 'spectype'):\n",
    "        if c == 'spectype':\n",
    "            columns.append(MaskedColumn([np.char.rstrip(getattr(row.ZCat, c)) for row in q], name=c.upper(), mask=mask))\n",
    "        else:\n",
    "            columns.append(MaskedColumn([getattr(row.ZCat, c) for row in q], name=c.upper(), mask=mask))\n",
    "    columns.append(MaskedColumn([row.dz for row in q], name='DZ', mask=mask))\n",
    "    t.add_columns(columns)\n",
    "    return t\n",
    "truth = truth_query_to_table(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('          ntarg   good  fail  miss  lost')\n",
    "for objtype in set(truth['TEMPLATETYPE']):\n",
    "    #isx = (truth['TEMPLATETYPE'] == objtype)\n",
    "    pgood, pfail, pmiss, plost, nx = dsq_z.zstats(truth, objtype=objtype)\n",
    "    #nx = np.count_nonzero(isx)\n",
    "    print('{:6s} {:8d}  {:5.1f} {:5.1f} {:5.1f} {:5.1f}'.format(objtype, nx, pgood, pfail, pmiss, plost))\n",
    "\n",
    "print()\n",
    "print('good = correct redshift and ZWARN==0')\n",
    "print('fail = bad redshift and ZWARN==0 (i.e. catastrophic failures)')\n",
    "print('miss = correct redshift ZWARN!=0 (missed opportunities)')\n",
    "print('lost = wrong redshift ZWARN!=0 (wrong but at least we know it)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Confusion matrix.  Borrowed from the minitest notebook.\n",
    "#\n",
    "confusion = dsq_z.spectype_confusion(truth)\n",
    "#\n",
    "# Pretty print the confusion matrix.\n",
    "#\n",
    "print('            Redrock')\n",
    "print('Truth     ', end='')\n",
    "for s1 in confusion:\n",
    "    print('{:>8s}'.format(s1), end='')\n",
    "print()\n",
    "for s1 in confusion:\n",
    "    print('{:8s}  '.format(s1), end='')\n",
    "    for s2 in confusion:\n",
    "        try:\n",
    "            print('{:8d}'.format(confusion[s1][s2]), end='')\n",
    "        except KeyError:\n",
    "            print('{:8d}'.format(0), end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Obtain detailed statistics for all objects.\n",
    "#\n",
    "stats = dict()\n",
    "for s in np.unique(truth['TEMPLATETYPE']):\n",
    "    stats[s] = dsq_z.calc_obj_stats(truth, s)\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going Beyond the Summary\n",
    "\n",
    "Summary statistics are useful, but they don't tell how efficiency and other parameters depend on each other.  How does efficiency depend on magnitude?  Moon in the sky?\n",
    "\n",
    "Some capability exists to do this in `desisim.spec_qa.redshifts`, but we'll start with a basic example just to get the feel of plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# ZWARNING versus magnitude.\n",
    "#\n",
    "g = 22.5 - 2.5*np.log10(truth['FLUX_G'])\n",
    "r = 22.5 - 2.5*np.log10(truth['FLUX_R'])\n",
    "z = 22.5 - 2.5*np.log10(truth['FLUX_Z'])\n",
    "fig, axes = plt.subplots(3, 1, figsize=(8, 4.5*3), dpi=100)\n",
    "p = axes[0].plot(g, truth['ZWARN'], 'k.')\n",
    "foo = axes[0].set_xlim(axes[0].get_xlim()[1], axes[0].get_xlim()[0])\n",
    "foo = axes[0].grid(True)\n",
    "# foo = axes[0].set_xlabel('g Magnitude')\n",
    "foo = axes[0].set_ylabel('ZWARNING')\n",
    "p = axes[1].plot(g, truth['ZWARN'], 'k.')\n",
    "foo = axes[1].set_xlim(axes[1].get_xlim()[1], axes[1].get_xlim()[0])\n",
    "foo = axes[1].set_ylim(0, 50)\n",
    "foo = axes[1].grid(True)\n",
    "# foo = axes[1].set_xlabel('g Magnitude')\n",
    "foo = axes[1].set_ylabel('ZWARNING')\n",
    "p = axes[2].plot(g, truth['ZWARN'], 'k.')\n",
    "foo = axes[2].set_xlim(axes[2].get_xlim()[1], axes[2].get_xlim()[0])\n",
    "foo = axes[2].set_ylim(0, 5)\n",
    "foo = axes[2].grid(True)\n",
    "foo = axes[2].set_xlabel('g Magnitude')\n",
    "foo = axes[2].set_ylabel('ZWARNING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`desisim.spec_qa.redshifts.plot_slices()` makes nice plots, so we'll leverage that for a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Only return a subset of columns, and then use zip() to go from row-based to column-based.\n",
    "#\n",
    "q = db.dbSession.query(db.Truth.truez, db.ZCat.z, db.ZCat.zwarn, db.Target.flux_g, \n",
    "                       ((db.ZCat.z - db.Truth.truez)/(1.0 + db.Truth.truez)).label('dz'))\\\n",
    "                .filter(db.Truth.targetid == db.ZCat.targetid).filter(db.Target.targetid == db.ZCat.targetid).all()    \n",
    "truez, z, zwarn, flux_g, dz = zip(*q)\n",
    "g = 22.5 - 2.5*np.log10(np.array(flux_g))\n",
    "ok = np.array(zwarn) == 0\n",
    "dv = lightspeed.to('km / s').value * np.array(dz)\n",
    "bad = (np.abs(dv) > 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(8, 4.5), dpi=100)\n",
    "p = dsq_z.plot_slices(g, dv, ok, bad, 16, 25, 1000, num_slices=20, axis=axes)\n",
    "foo = axes.set_xlabel('g Magnitude')\n",
    "foo = axes.set_ylabel('Velocity Residual [km / s]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "* Plot a particular template class, *e.g.* 'QSO_T'.\n",
    "* Plot versus other magnitudes, *e.g.* r, W1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fly me to the Moon\n",
    "\n",
    "How does the Moon affect redshifts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# How many actual exposures are there with the Moon up?\n",
    "#\n",
    "q = db.dbSession.query(db.ObsList.expid, db.ObsList.moonsep, db.ObsList.moonalt, db.ObsList.moonfrac).filter(db.ObsList.moonalt > 0).all()\n",
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are a few.  But there is a subtle issue: redshifts are based on *all* exposures, but maybe there are some redshifts where the object was observed *only* with the Moon up. And we can try to compare those objects to similar objects observed *only* with the Moon down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expid_up = [x[0] for x in q]\n",
    "q = db.dbSession.query(db.ZCat.targetid, db.Target.desi_target, db.Target.bgs_target, db.Target.mws_target, db.ObsList.expid)\\\n",
    "                .filter(db.ZCat.targetid == db.FiberAssign.targetid)\\\n",
    "                .filter(db.ZCat.targetid == db.Target.targetid)\\\n",
    "                .filter(db.FiberAssign.tileid == db.ObsList.tileid)\\\n",
    "                .filter(db.ObsList.expid.in_(expid_up))\\\n",
    "                .order_by(db.ZCat.targetid, db.ObsList.expid).all()\n",
    "targetid, desi_target, bgs_target, mws_target, expid = zip(*q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(['ELG' in desi_mask.names(t) for t in desi_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# OK, let's find some ELGs with the Moon up, and some with the Moon down.\n",
    "#\n",
    "q_up = db.dbSession.query(db.ZCat.targetid, db.Truth.truez, db.ZCat.z, db.ZCat.zwarn,\n",
    "                       ((db.ZCat.z - db.Truth.truez)/(1.0 + db.Truth.truez)).label('dz'))\\\n",
    "                   .filter(db.Truth.targetid == db.ZCat.targetid)\\\n",
    "                   .filter(db.Target.targetid == db.ZCat.targetid)\\\n",
    "                   .filter(db.ZCat.targetid == db.FiberAssign.targetid)\\\n",
    "                   .filter(db.FiberAssign.tileid == db.ObsList.tileid)\\\n",
    "                   .filter(db.ObsList.expid.in_(expid_up))\\\n",
    "                   .filter(db.Target.desi_target.op('&')(desi_mask.ELG) != 0)\\\n",
    "                   .all()\n",
    "q_dn = db.dbSession.query(db.ZCat.targetid, db.Truth.truez, db.ZCat.z, db.ZCat.zwarn,\n",
    "                       ((db.ZCat.z - db.Truth.truez)/(1.0 + db.Truth.truez)).label('dz'))\\\n",
    "                   .filter(db.Truth.targetid == db.ZCat.targetid)\\\n",
    "                   .filter(db.Target.targetid == db.ZCat.targetid)\\\n",
    "                   .filter(db.ZCat.targetid == db.FiberAssign.targetid)\\\n",
    "                   .filter(db.FiberAssign.tileid == db.ObsList.tileid)\\\n",
    "                   .filter(~db.ObsList.expid.in_(expid_up))\\\n",
    "                   .filter(db.Target.desi_target.op('&')(desi_mask.ELG) != 0)\\\n",
    "                   .all()[:8342]\n",
    "foo, truez_up, z_up, zwarn_up, dz_up = zip(*q_up)\n",
    "foo, truez_dn, z_dn, zwarn_dn, dz_dn = zip(*q_dn)\n",
    "truez_up = np.array(truez_up)\n",
    "z_up = np.array(z_up)\n",
    "zwarn_up = np.array(zwarn_up)\n",
    "dv_up = lightspeed.to('km / s').value * np.array(dz_up)\n",
    "truez_dn = np.array(truez_dn)\n",
    "z_dn = np.array(z_dn)\n",
    "zwarn_dn = np.array(zwarn_dn)\n",
    "dv_dn = lightspeed.to('km / s').value * np.array(dz_dn)\n",
    "ok_up = zwarn_up == 0\n",
    "ok_dn = zwarn_dn == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Observed redshift versus true redshift.\n",
    "#\n",
    "fig, axes = plt.subplots(1, 1, figsize=(8, 8), dpi=100)\n",
    "p1 = axes.plot(truez_up[ok_up], z_up[ok_up], 'r.', label='Up')\n",
    "p2 = axes.plot(truez_dn[ok_dn], z_dn[ok_dn], 'b.', label='Down')\n",
    "foo = axes.set_xlabel('True redshift')\n",
    "foo = axes.set_ylabel('Pipeline redshift')\n",
    "foo = axes.legend(loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Velocity residual versus true redshift.\n",
    "#\n",
    "fig, axes = plt.subplots(1, 1, figsize=(8, 8), dpi=100)\n",
    "p1 = axes.semilogy(truez_up[ok_up], np.abs(dv_up[ok_up]), 'r.', label='Up')\n",
    "p2 = axes.semilogy(truez_dn[ok_dn], np.abs(dv_dn[ok_dn]), 'b.', label='Down')\n",
    "foo = axes.set_xlabel('True redshift')\n",
    "foo = axes.set_ylabel('Absolute Velocity residual [km/s]')\n",
    "foo = axes.legend(loc=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, there doesn't appear to be much difference here.  That's not necessarily a bad thing!\n",
    "\n",
    "### Exercise\n",
    "\n",
    "* Try a different target class!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey Progress\n",
    "\n",
    "Let's see which nights have science data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = db.dbSession.query(db.ObsList.night, func.count('*').label('n_science'))\\\n",
    "                .filter(db.ObsList.flavor == 'science')\\\n",
    "                .group_by(db.ObsList.night).order_by(db.ObsList.night).all()\n",
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation timestamp for a given night."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = db.dbSession.query(db.ObsList.expid, db.ObsList.mjd)\\\n",
    "                .filter(db.ObsList.flavor == 'science')\\\n",
    "                .filter(db.ObsList.night == '20200317')\\\n",
    "                .order_by(db.ObsList.mjd).all()\n",
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for a given target in the `target` table, when was the observation completed?  In other words, if a target has multiple observations, we want the date of the *last* observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# How many targets are there?\n",
    "#\n",
    "N_targets = db.dbSession.query(db.Target).count()\n",
    "N_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Find all targetids that have observations.\n",
    "#\n",
    "q1 = db.dbSession.query(db.Target.targetid)\\\n",
    "                .filter(db.Target.targetid == db.FiberAssign.targetid)\\\n",
    "                .filter(db.FiberAssign.tileid == db.ObsList.tileid)\\\n",
    "                .group_by(db.Target.targetid)\\\n",
    "                .subquery()\n",
    "#\n",
    "# Find the exposure times for the targetids that have been observed\n",
    "#\n",
    "q2 = db.dbSession.query(db.FiberAssign.targetid, db.ObsList.expid, db.ObsList.mjd)\\\n",
    "                 .filter(db.FiberAssign.targetid == q1.c.targetid)\\\n",
    "                 .filter(db.FiberAssign.tileid == db.ObsList.tileid)\\\n",
    "                 .order_by(q1.c.targetid, db.ObsList.expid).all()\n",
    "targetid, expid, mjd = zip(*q2)\n",
    "targetid = np.array(targetid)\n",
    "expid = np.array(expid)\n",
    "mjd = np.array(mjd)\n",
    "#\n",
    "# Use the counts to give the *last* observation.\n",
    "#\n",
    "unique_targetid, i, j, c = np.unique(targetid, return_index=True, return_inverse=True, return_counts=True)\n",
    "unique_expid = expid[i + (c-1)]\n",
    "unique_mjd = mjd[i + (c-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Now we have the targets and the date of last observation.  But it's sorted by targetid.\n",
    "#\n",
    "ii = unique_expid.argsort()\n",
    "unique_targetid, i3, j3, c3 = np.unique(unique_expid[ii], return_index=True, return_inverse=True, return_counts=True)\n",
    "N_completed = np.cumsum(c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(8, 8), dpi=100)\n",
    "p1 = axes.plot(unique_mjd[ii][i3] - 58920, N_completed/N_targets, 'k-')\n",
    "foo = axes.set_xlabel('MJD - 58920')\n",
    "foo = axes.set_ylabel('Fraction completed')\n",
    "foo = axes.grid(True)\n",
    "# foo = axes.legend(loc=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "* Break down the progress by target class, target bit, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DESI custom",
   "language": "python",
   "name": "desi-custom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
